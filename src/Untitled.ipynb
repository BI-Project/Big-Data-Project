{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\82109\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\82109\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\82109\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\82109\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20201.txt',\n",
       " '202010.txt',\n",
       " '202011.txt',\n",
       " '20202.txt',\n",
       " '20203.txt',\n",
       " '20204.txt',\n",
       " '20205.txt',\n",
       " '20206.txt',\n",
       " '20207.txt',\n",
       " '20208.txt',\n",
       " '20209.txt']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/news_script_integrated/\"\n",
    "news_list = sorted(os.listdir(data_path))\n",
    "news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame()\n",
    "stemmer = WordNetLemmatizer()\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', text)\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    return document    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'country', 'with', 'one', 'of', 'the', 'world', 'lowest', 'birth', 'rate', 'one', 'would', 'assume', 'the', 'news', 'of', 'beloved', 'celebrity', 'announcing', 'plan', 'for', 'marriage', 'and', 'an', 'imminent', 'child', 'would', 'be', 'welcomed', 'with', 'open', 'arm'], [], ['but', 'not', 'in', 'korea', 'and', 'not', 'for', 'k', 'pop', 'idol'], [], ['chen', 'member', 'of', 'one', 'of', 'the', 'country', 'most', 'successful', 'pop', 'group', 'exo', 'announced', 'in', 'handwritten', 'letter', 'posted', 'on', 'social', 'medium', 'that', 'he', 'wa', 'doing', 'exactly', 'this'], [], ['yet', 'much', 'of', 'the', 'response', 'from', 'fan', 'wa', 'both', 'toxic', 'and', 'unpleasant', 'many', 'called', 'on', 'him', 'to', 'leave', 'the', 'group', 'immediately', 'and', 'spoke', 'of', 'the', 'betrayal', 'that', 'they', 'felt'], [], ['such', 'devil', 'comment', 'ang', 'pul', 'a', 'they', 'are', 'known', 'in', 'korean', 'should', 'not', 'be', 'taken', 'lightly', 'a', 'the', 'recent', 'suicide', 'of', 'pop', 'star', 'sulli', 'and', 'goo', 'hara', 'have', 'been', 'linked', 'to', 'the', 'negative', 'treatment', 'they', 'received', 'online'], []]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(news_list)):\n",
    "    f = open(data_path + news_list[i], 'r', encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    text = []\n",
    "    for line in lines[:10]:\n",
    "        t\n",
    "        text.append(text_preprocess(line).split())\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'country',\n",
       " 'with',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'lowest',\n",
       " 'birth',\n",
       " 'rate',\n",
       " 'one',\n",
       " 'would',\n",
       " 'assume',\n",
       " 'the',\n",
       " 'news',\n",
       " 'of',\n",
       " 'beloved',\n",
       " 'celebrity',\n",
       " 'announcing',\n",
       " 'plan',\n",
       " 'for',\n",
       " 'marriage',\n",
       " 'and',\n",
       " 'an',\n",
       " 'imminent',\n",
       " 'child',\n",
       " 'would',\n",
       " 'be',\n",
       " 'welcomed',\n",
       " 'with',\n",
       " 'open',\n",
       " 'arm',\n",
       " 'but',\n",
       " 'not',\n",
       " 'in',\n",
       " 'korea',\n",
       " 'and',\n",
       " 'not',\n",
       " 'for',\n",
       " 'k',\n",
       " 'pop',\n",
       " 'idol',\n",
       " 'chen',\n",
       " 'member',\n",
       " 'of',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " 'most',\n",
       " 'successful',\n",
       " 'pop',\n",
       " 'group',\n",
       " 'exo',\n",
       " 'announced',\n",
       " 'in',\n",
       " 'handwritten',\n",
       " 'letter',\n",
       " 'posted',\n",
       " 'on',\n",
       " 'social',\n",
       " 'medium',\n",
       " 'that',\n",
       " 'he',\n",
       " 'wa',\n",
       " 'doing',\n",
       " 'exactly',\n",
       " 'this',\n",
       " 'yet',\n",
       " 'much',\n",
       " 'of',\n",
       " 'the',\n",
       " 'response',\n",
       " 'from',\n",
       " 'fan',\n",
       " 'wa',\n",
       " 'both',\n",
       " 'toxic',\n",
       " 'and',\n",
       " 'unpleasant',\n",
       " 'many',\n",
       " 'called',\n",
       " 'on',\n",
       " 'him',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'the',\n",
       " 'group',\n",
       " 'immediately',\n",
       " 'and',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'the',\n",
       " 'betrayal',\n",
       " 'that',\n",
       " 'they',\n",
       " 'felt',\n",
       " 'such',\n",
       " 'devil',\n",
       " 'comment',\n",
       " 'ang',\n",
       " 'pul',\n",
       " 'a',\n",
       " 'they',\n",
       " 'are',\n",
       " 'known',\n",
       " 'in',\n",
       " 'korean',\n",
       " 'should',\n",
       " 'not',\n",
       " 'be',\n",
       " 'taken',\n",
       " 'lightly',\n",
       " 'a',\n",
       " 'the',\n",
       " 'recent',\n",
       " 'suicide',\n",
       " 'of',\n",
       " 'pop',\n",
       " 'star',\n",
       " 'sulli',\n",
       " 'and',\n",
       " 'goo',\n",
       " 'hara',\n",
       " 'have',\n",
       " 'been',\n",
       " 'linked',\n",
       " 'to',\n",
       " 'the',\n",
       " 'negative',\n",
       " 'treatment',\n",
       " 'they',\n",
       " 'received',\n",
       " 'online',\n",
       " 'twitter',\n",
       " 'wa',\n",
       " 'filled',\n",
       " 'with',\n",
       " 'hashtags',\n",
       " 'retweeted',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ten',\n",
       " 'of',\n",
       " 'thousand',\n",
       " 'wildly',\n",
       " 'criticizing',\n",
       " 'chen',\n",
       " 'for',\n",
       " 'his',\n",
       " 'perceived',\n",
       " 'crime',\n",
       " 'and',\n",
       " 'inconsiderate',\n",
       " 'behavior',\n",
       " 'the',\n",
       " 'atmosphere',\n",
       " 'a',\n",
       " 'is',\n",
       " 'often',\n",
       " 'the',\n",
       " 'case',\n",
       " 'wa',\n",
       " 'full',\n",
       " 'of',\n",
       " 'self',\n",
       " 'righteousness',\n",
       " 'and',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'humility',\n",
       " 'and',\n",
       " 'consideration',\n",
       " 'thing',\n",
       " 'went',\n",
       " 'step',\n",
       " 'further',\n",
       " 'when',\n",
       " 'the',\n",
       " 'official',\n",
       " 'exo',\n",
       " 'fan',\n",
       " 'group',\n",
       " 'released',\n",
       " 'statement',\n",
       " 'demanding',\n",
       " 'chen',\n",
       " 'leave',\n",
       " 'the',\n",
       " 'group',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'they',\n",
       " 'could',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'support',\n",
       " 'him',\n",
       " 'and',\n",
       " 'that',\n",
       " 'his',\n",
       " 'arbitrary',\n",
       " 'action',\n",
       " 'were',\n",
       " 'damaging',\n",
       " 'the',\n",
       " 'group',\n",
       " 'reputation',\n",
       " 'the',\n",
       " 'fan',\n",
       " 'group',\n",
       " 'known',\n",
       " 'a',\n",
       " 'exo',\n",
       " 'ace',\n",
       " 'union',\n",
       " 'have',\n",
       " 'warned',\n",
       " 'that',\n",
       " 'they',\n",
       " 'will',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'protest',\n",
       " 'in',\n",
       " 'response',\n",
       " 'and',\n",
       " 'expect',\n",
       " 'action',\n",
       " 'from',\n",
       " 'the',\n",
       " 'management',\n",
       " 'sm',\n",
       " 'entertainment',\n",
       " 'and',\n",
       " 'remember',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'for',\n",
       " 'story',\n",
       " 'involving',\n",
       " 'drug',\n",
       " 'sexual',\n",
       " 'misadventure',\n",
       " 'or',\n",
       " 'violence',\n",
       " 'it',\n",
       " 'for',\n",
       " 'marriage',\n",
       " 'and',\n",
       " 'chen',\n",
       " 'situation',\n",
       " 'is',\n",
       " 'not',\n",
       " 'the',\n",
       " 'first',\n",
       " 'sunye',\n",
       " 'wa',\n",
       " 'the',\n",
       " 'leader',\n",
       " 'of',\n",
       " 'the',\n",
       " 'wonder',\n",
       " 'girl',\n",
       " 'but',\n",
       " 'left',\n",
       " 'the',\n",
       " 'team',\n",
       " 'to',\n",
       " 'marry',\n",
       " 'her',\n",
       " 'husband',\n",
       " 'and',\n",
       " 'raise',\n",
       " 'her',\n",
       " 'two',\n",
       " 'daughter',\n",
       " 'in',\n",
       " 'canada',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'support',\n",
       " 'her',\n",
       " 'nascent',\n",
       " 'family',\n",
       " 'many',\n",
       " 'netizens',\n",
       " 'spoke',\n",
       " 'out',\n",
       " 'angrily',\n",
       " 'at',\n",
       " 'the',\n",
       " 'hurt',\n",
       " 'and',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'loyalty',\n",
       " 'she',\n",
       " 'demonstrated',\n",
       " 'the',\n",
       " 'same',\n",
       " 'treatment',\n",
       " 'wa',\n",
       " 'given',\n",
       " 'to',\n",
       " 'super',\n",
       " 'junior',\n",
       " 'sungmin',\n",
       " 'when',\n",
       " 'he',\n",
       " 'married',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'back',\n",
       " 'in',\n",
       " '2014',\n",
       " 'he',\n",
       " 'wa',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'mistreating',\n",
       " 'his',\n",
       " 'fan',\n",
       " 'and',\n",
       " 'his',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'group',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'vehemently',\n",
       " 'opposed',\n",
       " 'by',\n",
       " 'an',\n",
       " 'army',\n",
       " 'of',\n",
       " 'online',\n",
       " 'commentator',\n",
       " 'to',\n",
       " 'most',\n",
       " 'of',\n",
       " 'u',\n",
       " 'who',\n",
       " 'are',\n",
       " 'not',\n",
       " 'devoted',\n",
       " 'and',\n",
       " 'committed',\n",
       " 'fan',\n",
       " 'what',\n",
       " 'is',\n",
       " 'it',\n",
       " 'there',\n",
       " 'to',\n",
       " 'be',\n",
       " 'mad',\n",
       " 'about',\n",
       " 'are',\n",
       " 'marriage',\n",
       " 'and',\n",
       " 'the',\n",
       " 'birth',\n",
       " 'of',\n",
       " 'baby',\n",
       " 'not',\n",
       " 'something',\n",
       " 'to',\n",
       " 'celebrate',\n",
       " 'the',\n",
       " 'disappointment',\n",
       " 'and',\n",
       " 'anger',\n",
       " 'that',\n",
       " 'ha',\n",
       " 'arisen',\n",
       " 'ha',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'how',\n",
       " 'the',\n",
       " 'pop',\n",
       " 'industry',\n",
       " 'operates',\n",
       " 'it',\n",
       " 'is',\n",
       " 'manifestation',\n",
       " 'of',\n",
       " 'how',\n",
       " 'the',\n",
       " 'relationship',\n",
       " 'between',\n",
       " 'artist',\n",
       " 'in',\n",
       " 'the',\n",
       " 'loosest',\n",
       " 'sense',\n",
       " 'and',\n",
       " 'fan',\n",
       " 'are',\n",
       " 'formed',\n",
       " 'a',\n",
       " 'well',\n",
       " 'a',\n",
       " 'the',\n",
       " 'consumption',\n",
       " 'of',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'idol',\n",
       " 'a',\n",
       " 'product',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'pop',\n",
       " 'artist',\n",
       " 'are',\n",
       " 'born',\n",
       " 'a',\n",
       " 'product',\n",
       " 'mere',\n",
       " 'merchandise',\n",
       " 'of',\n",
       " 'an',\n",
       " 'entertainment',\n",
       " 'company',\n",
       " 'they',\n",
       " 'are',\n",
       " 'designed',\n",
       " 'and',\n",
       " 'constructed',\n",
       " 'through',\n",
       " 'the',\n",
       " 'company',\n",
       " 'know',\n",
       " 'how',\n",
       " 'including',\n",
       " 'the',\n",
       " 'person',\n",
       " 'aesthetic',\n",
       " 'look',\n",
       " 'the',\n",
       " 'music',\n",
       " 'genre',\n",
       " 'and',\n",
       " 'the',\n",
       " 'character',\n",
       " 'or',\n",
       " 'concept',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'done',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'attract',\n",
       " 'a',\n",
       " 'many',\n",
       " 'fan',\n",
       " 'a',\n",
       " 'possible',\n",
       " 'thus',\n",
       " 'generating',\n",
       " 'profit',\n",
       " 'for',\n",
       " 'the',\n",
       " 'company',\n",
       " 'moreover',\n",
       " 'the',\n",
       " 'designed',\n",
       " 'product',\n",
       " 'is',\n",
       " 'often',\n",
       " 'young',\n",
       " 'child',\n",
       " 'who',\n",
       " 'dream',\n",
       " 'of',\n",
       " 'dancing',\n",
       " 'and',\n",
       " 'singing',\n",
       " 'on',\n",
       " 'stage',\n",
       " 'autonomy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'word',\n",
       " 'one',\n",
       " 'should',\n",
       " 'readily',\n",
       " 'associate',\n",
       " 'with',\n",
       " 'these',\n",
       " 'product',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'expressing',\n",
       " 'themselves',\n",
       " 'freely',\n",
       " 'and',\n",
       " 'naturally',\n",
       " 'many',\n",
       " 'are',\n",
       " 'simply',\n",
       " 'following',\n",
       " 'the',\n",
       " 'order',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'of',\n",
       " 'the',\n",
       " 'company',\n",
       " 'whom',\n",
       " 'they',\n",
       " 'serve',\n",
       " 'something',\n",
       " 'not',\n",
       " 'that',\n",
       " 'unusual',\n",
       " 'in',\n",
       " 'the',\n",
       " 'broadly',\n",
       " 'collective',\n",
       " 'and',\n",
       " 'hierarchical',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'korean',\n",
       " 'society',\n",
       " 'people',\n",
       " 'inside',\n",
       " 'the',\n",
       " 'industry',\n",
       " 'also',\n",
       " 'speak',\n",
       " 'openly',\n",
       " 'of',\n",
       " 'the',\n",
       " 'service',\n",
       " 'their',\n",
       " 'entertainment',\n",
       " 'company',\n",
       " 'provide',\n",
       " 'form',\n",
       " 'of',\n",
       " 'surrogate',\n",
       " 'dating',\n",
       " 'virtual',\n",
       " 'boyfriend',\n",
       " 'or',\n",
       " 'girlfriend',\n",
       " 'experience',\n",
       " 'created',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fan',\n",
       " 'moreover',\n",
       " 'because',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'idol',\n",
       " 'formation',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'be',\n",
       " 'that',\n",
       " 'of',\n",
       " 'group',\n",
       " 'normally',\n",
       " 'around',\n",
       " '5',\n",
       " '9',\n",
       " 'member',\n",
       " 'but',\n",
       " 'sometimes',\n",
       " 'a',\n",
       " 'many',\n",
       " 'a',\n",
       " '17',\n",
       " 'individuality',\n",
       " 'is',\n",
       " 'not',\n",
       " 'key',\n",
       " 'component',\n",
       " 'the',\n",
       " 'key',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trainee',\n",
       " 'to',\n",
       " 'adjust',\n",
       " 'themselves',\n",
       " 'to',\n",
       " 'the',\n",
       " 'tone',\n",
       " 'of',\n",
       " 'the',\n",
       " 'collective',\n",
       " 'even',\n",
       " 'if',\n",
       " 'it',\n",
       " 'clash',\n",
       " 'with',\n",
       " 'their',\n",
       " 'own',\n",
       " 'personality',\n",
       " 'or',\n",
       " 'wish',\n",
       " 'thus',\n",
       " 'an',\n",
       " 'agony',\n",
       " 'arises',\n",
       " 'when',\n",
       " 'the',\n",
       " 'individual',\n",
       " 'member',\n",
       " 'is',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'between',\n",
       " 'their',\n",
       " 'own',\n",
       " 'path',\n",
       " 'and',\n",
       " 'that',\n",
       " 'of',\n",
       " 'the',\n",
       " 'group',\n",
       " 'either',\n",
       " 'artistically',\n",
       " 'personally',\n",
       " 'or',\n",
       " 'otherwise',\n",
       " 'this',\n",
       " 'will',\n",
       " 'always',\n",
       " 'remain',\n",
       " 'an',\n",
       " 'existing',\n",
       " 'concern',\n",
       " 'yet',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'necessarily',\n",
       " 'unique',\n",
       " 'to',\n",
       " 'pop',\n",
       " 'it',\n",
       " 'doe',\n",
       " 'however',\n",
       " 'demonstrate',\n",
       " 'how',\n",
       " 'and',\n",
       " 'why',\n",
       " 'chen',\n",
       " 'a',\n",
       " 'member',\n",
       " 'of',\n",
       " 'group',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'to',\n",
       " 'face',\n",
       " 'such',\n",
       " 'public',\n",
       " 'criticism',\n",
       " 'for',\n",
       " 'merely',\n",
       " 'having',\n",
       " 'the',\n",
       " 'temerity',\n",
       " 'to',\n",
       " 'follow',\n",
       " 'his',\n",
       " 'own',\n",
       " 'path',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'his',\n",
       " 'teammate',\n",
       " 'of',\n",
       " 'course',\n",
       " 'pop',\n",
       " 'is',\n",
       " 'inspiring',\n",
       " 'and',\n",
       " 'brings',\n",
       " 'joy',\n",
       " 'and',\n",
       " 'happiness',\n",
       " 'to',\n",
       " 'million',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " 'promoting',\n",
       " 'welcoming',\n",
       " 'message',\n",
       " 'and',\n",
       " 'increasing',\n",
       " 'the',\n",
       " 'representation',\n",
       " 'of',\n",
       " 'asian',\n",
       " 'on',\n",
       " 'the',\n",
       " 'global',\n",
       " 'stage',\n",
       " 'while',\n",
       " 'helping',\n",
       " 'to',\n",
       " 'weaken',\n",
       " 'racism',\n",
       " 'and',\n",
       " 'promote',\n",
       " 'greater',\n",
       " 'awareness',\n",
       " 'from',\n",
       " 'the',\n",
       " 'other',\n",
       " 'side',\n",
       " 'however',\n",
       " 'one',\n",
       " 'article',\n",
       " 'recently',\n",
       " 'likened',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'pop',\n",
       " 'fandom',\n",
       " 'to',\n",
       " 'the',\n",
       " 'rabid',\n",
       " 'and',\n",
       " 'sometimes',\n",
       " 'ugly',\n",
       " 'support',\n",
       " 'that',\n",
       " 'we',\n",
       " 'see',\n",
       " 'in',\n",
       " 'football',\n",
       " 'yes',\n",
       " 'football',\n",
       " 'is',\n",
       " 'the',\n",
       " 'beautiful',\n",
       " 'game',\n",
       " 'but',\n",
       " 'it',\n",
       " 'would',\n",
       " 'be',\n",
       " 'wrong',\n",
       " 'to',\n",
       " 'say',\n",
       " 'there',\n",
       " 'isn',\n",
       " 'often',\n",
       " 'dark',\n",
       " 'side',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fandom',\n",
       " 'and',\n",
       " 'that',\n",
       " 'it',\n",
       " 'differs',\n",
       " 'in',\n",
       " 'each',\n",
       " 'country',\n",
       " 'in',\n",
       " 'how',\n",
       " 'it',\n",
       " 'manifest',\n",
       " 'from',\n",
       " 'hooligan',\n",
       " 'to',\n",
       " 'racism',\n",
       " 'to',\n",
       " 'wit',\n",
       " 'recent',\n",
       " 'study',\n",
       " 'out',\n",
       " 'of',\n",
       " 'korea',\n",
       " 'university',\n",
       " 'and',\n",
       " 'published',\n",
       " 'in',\n",
       " 'the',\n",
       " 'academic',\n",
       " 'journal',\n",
       " 'asian',\n",
       " 'woman',\n",
       " 'suggested',\n",
       " 'that',\n",
       " 'the',\n",
       " 'more',\n",
       " 'money',\n",
       " 'people',\n",
       " 'spend',\n",
       " 'on',\n",
       " 'pop',\n",
       " 'the',\n",
       " 'le',\n",
       " 'egalitarian',\n",
       " 'gender',\n",
       " 'value',\n",
       " 'they',\n",
       " 'are',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'demonstrate',\n",
       " 'perhaps',\n",
       " 'the',\n",
       " 'recent',\n",
       " 'case',\n",
       " 'involving',\n",
       " 'chen',\n",
       " 'increase',\n",
       " 'the',\n",
       " 'explanatory',\n",
       " 'power',\n",
       " 'of',\n",
       " 'that',\n",
       " 'research',\n",
       " 'following',\n",
       " 'the',\n",
       " 'arrival',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bestselling',\n",
       " 'book',\n",
       " 'trend',\n",
       " '2020',\n",
       " 'the',\n",
       " 'follower',\n",
       " 'of',\n",
       " 'pop',\n",
       " 'have',\n",
       " 'been',\n",
       " 'renamed',\n",
       " 'fan',\n",
       " 'sumer',\n",
       " 'consumer',\n",
       " 'who',\n",
       " 'use',\n",
       " 'their',\n",
       " 'influence',\n",
       " 'a',\n",
       " 'fan',\n",
       " 'to',\n",
       " 'affect',\n",
       " 'how',\n",
       " 'the',\n",
       " 'product',\n",
       " 'in',\n",
       " 'this',\n",
       " 'case',\n",
       " 'the',\n",
       " 'pop',\n",
       " 'idol',\n",
       " 'is',\n",
       " 'marketed',\n",
       " 'and',\n",
       " 'presented',\n",
       " 'the',\n",
       " 'fansumer',\n",
       " 'culture',\n",
       " 'ha',\n",
       " 'arrived',\n",
       " 'in',\n",
       " 'line',\n",
       " 'with',\n",
       " 'social',\n",
       " 'medium',\n",
       " 'providing',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'their',\n",
       " 'voice',\n",
       " 'to',\n",
       " 'be',\n",
       " 'heard',\n",
       " 'and',\n",
       " 'generational',\n",
       " 'shift',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'boomer',\n",
       " 'and',\n",
       " 'latte',\n",
       " 'is',\n",
       " 'horse',\n",
       " 'people',\n",
       " 'to',\n",
       " 'millennial',\n",
       " 'and',\n",
       " 'generation',\n",
       " 'consumer',\n",
       " 'being',\n",
       " 'pop',\n",
       " 'idol',\n",
       " 'tv',\n",
       " 'star',\n",
       " 'or',\n",
       " 'celebrity',\n",
       " 'is',\n",
       " 'mostly',\n",
       " 'about',\n",
       " 'maintaining',\n",
       " 'your',\n",
       " 'popularity',\n",
       " 'this',\n",
       " 'is',\n",
       " 'achieved',\n",
       " 'by',\n",
       " 'winning',\n",
       " 'the',\n",
       " 'public',\n",
       " 'attention',\n",
       " 'interest',\n",
       " 'and',\n",
       " 'love',\n",
       " 'losing',\n",
       " 'this',\n",
       " 'popularity',\n",
       " 'a',\n",
       " 'celebrity',\n",
       " 'is',\n",
       " 'then',\n",
       " 'equal',\n",
       " 'to',\n",
       " 'an',\n",
       " 'enterprise',\n",
       " 'losing',\n",
       " 'customer',\n",
       " 'celebrity',\n",
       " 'are',\n",
       " 'expected',\n",
       " 'to',\n",
       " 'make',\n",
       " 'choice',\n",
       " 'with',\n",
       " 'which',\n",
       " 'the',\n",
       " 'public',\n",
       " 'will',\n",
       " 'agree',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'loving',\n",
       " 'themselves',\n",
       " 'they',\n",
       " 'are',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'adjust',\n",
       " 'themselves',\n",
       " 'to',\n",
       " 'the',\n",
       " 'want',\n",
       " 'and',\n",
       " 'need',\n",
       " 'of',\n",
       " 'the',\n",
       " 'consumer',\n",
       " 'the',\n",
       " 'fan',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'anytime',\n",
       " 'celebrity',\n",
       " 'doe',\n",
       " 'something',\n",
       " 'that',\n",
       " 'the',\n",
       " 'public',\n",
       " 'have',\n",
       " 'not',\n",
       " 'previously',\n",
       " 'agreed',\n",
       " 'or',\n",
       " 'consented',\n",
       " 'to',\n",
       " 'for',\n",
       " 'example',\n",
       " 'han',\n",
       " 'ye',\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['20201.txt'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "time Cbow_model = Word2Vec(data['20201.txt'].split(), size=100, window=3, min_count=1,  workers=1, sg=0, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['i', 'n', 'c', 'o', 'u', 't', 'r', 'y', 'w', 'h', 'e', 'f', 'l', 'd', 's', 'b', 'a', 'm', 'v', 'g', 'p', 'k', 'x', 'z', 'j', '2', '0', '1', '4', '5', '9', '7', 'q', '3', '6', '8', 'í', 'á', 'ú', 'ñ', 'ó', 'é', '대', '한', '민', '국', '중', '문', '화', '예', '술', '상', '레', '드', '벨', '벳', 'ł', 'ç', '_'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cbow_model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82109\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'is' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-8851e16f78cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCbow_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m                 )\n\u001b[1;32m-> 1447\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \"\"\"\n\u001b[1;32m-> 1397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'is' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "Cbow_model.most_similar(\"is\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
